#!/usr/bin/env python3
"""
MoE æ¨¡å‹é…ç½®ç®¡ç†è„šæœ¬
ç”¨äºç®¡ç†å¤šä¸ª MoE æ¨¡å‹çš„ä¼˜åŒ–é…ç½®
"""

import json
import os
import argparse
from pathlib import Path

class MoEConfigManager:
    def __init__(self, config_root="./configs"):
        self.config_root = Path(config_root)
        self.config_root.mkdir(exist_ok=True)
        
        # æ¨¡å‹é…ç½®æ˜ å°„
        self.model_configs = {
            "qwen3_30b": {
                "model_path": "/home/rm01/models/dev/llm/Qwen3-30B-A3B-Instruct-2507-AWQ",
                "experts": 64,
                "intermediate_size": 18944,
                "hidden_size": 3584,
                "topk": 4,
                "category": "medium_moe"
            },
            "mixtral_8x7b": {
                "model_path": "mistralai/Mixtral-8x7B-Instruct-v0.1", 
                "experts": 8,
                "intermediate_size": 14336,
                "hidden_size": 4096,
                "topk": 2,
                "category": "small_moe"
            },
            "deepseek_v2": {
                "model_path": "deepseek-ai/DeepSeek-V2-Chat",
                "experts": 160,
                "intermediate_size": 12288,
                "hidden_size": 5120,
                "topk": 6,
                "category": "large_moe"
            }
        }
    
    def tune_model(self, model_name, tp_size=1, dtype="auto", batch_sizes=None):
        """ä¸ºæŒ‡å®šæ¨¡å‹è¿è¡Œè°ƒä¼˜"""
        if model_name not in self.model_configs:
            print(f"é”™è¯¯: æœªçŸ¥æ¨¡å‹ {model_name}")
            print(f"æ”¯æŒçš„æ¨¡å‹: {list(self.model_configs.keys())}")
            return False
            
        config = self.model_configs[model_name]
        model_path = config["model_path"]
        
        # è®¾ç½®é»˜è®¤æ‰¹æ¬¡å¤§å°
        if batch_sizes is None:
            if config["category"] == "small_moe":
                batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256]
            elif config["category"] == "medium_moe":
                batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]
            else:  # large_moe
                batch_sizes = [1, 2, 4, 8, 16, 32, 64]
        
        # åˆ›å»ºæ¨¡å‹ä¸“ç”¨ç›®å½•
        save_dir = self.config_root / model_name
        save_dir.mkdir(exist_ok=True)
        
        batch_str = " ".join(map(str, batch_sizes))
        
        # æ„å»ºå‘½ä»¤
        cmd = f"""python benchmark_moe.py \\
  --model {model_path} \\
  --tp-size {tp_size} \\
  --dtype {dtype} \\
  --batch-size {batch_str} \\
  --tune \\
  --save-dir {save_dir} \\
  --trust-remote-code \\
  --seed 42"""
        
        print(f"ä¸ºæ¨¡å‹ {model_name} è¿è¡Œè°ƒä¼˜...")
        print(f"å‘½ä»¤: {cmd}")
        print()
        
        # æ‰§è¡Œè°ƒä¼˜
        exit_code = os.system(cmd)
        return exit_code == 0
    
    def find_compatible_config(self, model_name, target_experts, target_intermediate):
        """å¯»æ‰¾å…¼å®¹çš„é…ç½®æ–‡ä»¶"""
        compatible_configs = []
        
        for config_dir in self.config_root.iterdir():
            if not config_dir.is_dir():
                continue
                
            for config_file in config_dir.glob("*.json"):
                # è§£ææ–‡ä»¶å E{experts}N{intermediate}_tp{tp}_{dtype}.json
                filename = config_file.stem
                try:
                    parts = filename.split("_")
                    e_part = parts[0]  # E64N9472
                    experts = int(e_part.split("N")[0][1:])  # å»æ‰ 'E'
                    intermediate = int(e_part.split("N")[1])
                    
                    # æ£€æŸ¥å…¼å®¹æ€§ (å…è®¸ä¸€å®šè¯¯å·®)
                    experts_ratio = abs(experts - target_experts) / target_experts
                    intermediate_ratio = abs(intermediate - target_intermediate) / target_intermediate
                    
                    if experts_ratio < 0.2 and intermediate_ratio < 0.2:  # 20% è¯¯å·®èŒƒå›´
                        compatible_configs.append({
                            "file": config_file,
                            "experts": experts,
                            "intermediate": intermediate,
                            "similarity": 1 - (experts_ratio + intermediate_ratio) / 2
                        })
                except (IndexError, ValueError):
                    continue
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        compatible_configs.sort(key=lambda x: x["similarity"], reverse=True)
        return compatible_configs
    
    def recommend_config(self, model_name):
        """ä¸ºæ¨¡å‹æ¨èé…ç½®"""
        if model_name not in self.model_configs:
            print(f"æœªçŸ¥æ¨¡å‹: {model_name}")
            return
            
        config = self.model_configs[model_name]
        experts = config["experts"]
        intermediate = config["intermediate_size"]
        
        print(f"ä¸ºæ¨¡å‹ {model_name} æ¨èé…ç½®:")
        print(f"  ä¸“å®¶æ•°: {experts}")
        print(f"  ä¸­é—´å±‚ç»´åº¦: {intermediate}")
        print()
        
        # æŸ¥æ‰¾ä¸“ç”¨é…ç½®
        model_config_dir = self.config_root / model_name
        if model_config_dir.exists():
            configs = list(model_config_dir.glob("*.json"))
            if configs:
                print("âœ… æ‰¾åˆ°ä¸“ç”¨é…ç½®:")
                for config_file in configs:
                    print(f"  - {config_file}")
                return
        
        # æŸ¥æ‰¾å…¼å®¹é…ç½®
        compatible = self.find_compatible_config(model_name, experts, intermediate)
        if compatible:
            print("ğŸ”„ æ‰¾åˆ°å…¼å®¹é…ç½®:")
            for cfg in compatible[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæœ€ç›¸ä¼¼çš„
                print(f"  - {cfg['file']} (ç›¸ä¼¼åº¦: {cfg['similarity']:.2f})")
        else:
            print("âŒ æœªæ‰¾åˆ°å…¼å®¹é…ç½®ï¼Œå»ºè®®è¿è¡Œè°ƒä¼˜:")
            print(f"  python config_manager.py tune {model_name}")

def main():
    parser = argparse.ArgumentParser(description="MoE é…ç½®ç®¡ç†å·¥å…·")
    parser.add_argument("action", choices=["tune", "recommend", "list"], 
                       help="æ“ä½œ: tune(è°ƒä¼˜), recommend(æ¨è), list(åˆ—å‡º)")
    parser.add_argument("model", nargs="?", help="æ¨¡å‹åç§°")
    parser.add_argument("--tp-size", type=int, default=1, help="å¼ é‡å¹¶è¡Œåº¦")
    parser.add_argument("--dtype", default="auto", help="æ•°æ®ç±»å‹")
    parser.add_argument("--batch-sizes", nargs="+", type=int, help="æ‰¹æ¬¡å¤§å°åˆ—è¡¨")
    
    args = parser.parse_args()
    
    manager = MoEConfigManager()
    
    if args.action == "list":
        print("æ”¯æŒçš„æ¨¡å‹:")
        for name, config in manager.model_configs.items():
            print(f"  {name}: {config['experts']}ä¸“å®¶, {config['category']}")
    
    elif args.action == "recommend":
        if not args.model:
            print("è¯·æŒ‡å®šæ¨¡å‹åç§°")
            return
        manager.recommend_config(args.model)
    
    elif args.action == "tune":
        if not args.model:
            print("è¯·æŒ‡å®šæ¨¡å‹åç§°")
            return
        success = manager.tune_model(args.model, args.tp_size, args.dtype, args.batch_sizes)
        if success:
            print(f"âœ… æ¨¡å‹ {args.model} è°ƒä¼˜å®Œæˆ")
        else:
            print(f"âŒ æ¨¡å‹ {args.model} è°ƒä¼˜å¤±è´¥")

if __name__ == "__main__":
    main()